{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e644c8",
   "metadata": {},
   "source": [
    "# ResNet-32 VAE with Perceptual Loss\n",
    "\n",
    "This notebook demonstrates semi-supervised learning on CIFAR-10 using a ResNet-32 backbone. The approach first trains a Variational Autoencoder (VAE) on the unlabeled portion of the dataset with perceptual loss. The learned encoder is then fine tuned on 500 labeled examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentations similar to recent SOTA methods\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10\n",
    "full_train = datasets.CIFAR10(root='data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "# Split 500 labeled examples, rest unlabeled\n",
    "indices = np.arange(len(full_train))\n",
    "train_idx, unlabeled_idx = train_test_split(indices, train_size=500, stratify=full_train.targets, random_state=42)\n",
    "labeled_set = Subset(full_train, train_idx)\n",
    "unlabeled_set = Subset(full_train, unlabeled_idx)\n",
    "\n",
    "val_set = datasets.CIFAR10(root='data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "labeled_loader = DataLoader(labeled_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "unlabeled_loader = DataLoader(unlabeled_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4025cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple ResNet-32 implementation for CIFAR-10\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        return out\n",
    "\n",
    "def make_layer(in_planes, planes, num_blocks, stride):\n",
    "    layers = [BasicBlock(in_planes, planes, stride)]\n",
    "    for _ in range(1, num_blocks):\n",
    "        layers.append(BasicBlock(planes, planes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet32(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = make_layer(16, 16, num_blocks=5, stride=1)\n",
    "        self.layer2 = make_layer(16, 32, num_blocks=5, stride=2)\n",
    "        self.layer3 = make_layer(32, 64, num_blocks=5, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet32VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        backbone = ResNet32(num_classes=latent_dim*2)\n",
    "        self.encoder = nn.Sequential(backbone.conv1, backbone.bn1, nn.ReLU(),\n",
    "                                     backbone.layer1, backbone.layer2, backbone.layer3, backbone.avgpool)\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 64)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        vgg = models.vgg16(pretrained=True)\n",
    "        self.vgg_features = nn.Sequential(*list(vgg.features)[:16])\n",
    "        for p in self.vgg_features.parameters():\n",
    "            p.requires_grad = False\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = torch.flatten(h, 1)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_fc(z)\n",
    "        h = h.view(-1, 64, 1, 1)\n",
    "        return self.decoder(h)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "def perceptual_loss(x, recon, vgg):\n",
    "    with torch.no_grad():\n",
    "        f_x = vgg(x)\n",
    "        f_recon = vgg(recon)\n",
    "    return nn.functional.l1_loss(f_recon, f_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet32VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data,_ in unlabeled_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(data)\n",
    "        rec_loss = nn.functional.mse_loss(recon, data)\n",
    "        p_loss = perceptual_loss(data, recon, model.vgg_features)\n",
    "        kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = rec_loss + 0.1*p_loss + 1e-3*kld\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}: VAE loss {total_loss/len(unlabeled_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = model.encoder\n",
    "classifier = ResNet32(num_classes=10)\n",
    "classifier.conv1 = encoder[0]\n",
    "classifier.bn1 = encoder[1]\n",
    "classifier.layer1 = encoder[3]\n",
    "classifier.layer2 = encoder[4]\n",
    "classifier.layer3 = encoder[5]\n",
    "classifier.avgpool = encoder[6]\n",
    "classifier.fc = nn.Linear(64, 10)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "optimizer_c = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    classifier.train()\n",
    "    total, correct = 0, 0\n",
    "    for data, targets in labeled_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        optimizer_c.zero_grad()\n",
    "        out = classifier(data)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "        optimizer_c.step()\n",
    "        pred = out.argmax(dim=1)\n",
    "        total += targets.size(0)\n",
    "        correct += pred.eq(targets).sum().item()\n",
    "    acc = 100.0 * correct / total\n",
    "    print(f'Epoch {epoch+1}: accuracy {acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
